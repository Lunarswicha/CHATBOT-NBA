import os
import pandas as pd
from tqdm import tqdm
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

def load_csv_data(file):
    """Charge un fichier CSV et le convertit en texte."""
    file_path = os.path.join("data", file)
    if os.path.exists(file_path):
        if os.path.getsize(file_path) == 0:  # ğŸ“Œ VÃ©rifie si le fichier est vide
            print(f"âš ï¸ Le fichier {file} est vide, il sera ignorÃ©.")
            return ""  # Retourne une chaÃ®ne vide pour Ã©viter les erreurs

        try:
            df = pd.read_csv(file_path, sep=",", on_bad_lines="skip", encoding="utf-8")
        except Exception:
            df = pd.read_csv(file_path, sep=";", on_bad_lines="skip", encoding="utf-8")

        return "\n".join(df.iloc[:, 0].dropna().astype(str))  # ğŸ“Œ Prend la premiÃ¨re colonne de texte disponible
    else:
        print(f"âš ï¸ Fichier introuvable : {file}, il sera ignorÃ©.")
        return ""
def chunk_text(text, chunk_size=3000, chunk_overlap=300):
    """Divise le texte en morceaux pour les embeddings."""
    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    print("ğŸ”„ Chunking en cours...")
    chunks = list(tqdm(splitter.split_text(text), desc="Progression du chunking"))
    return chunks

def create_embeddings(chunks, batch_size=500):
    """GÃ©nÃ¨re et enregistre les embeddings avec FAISS."""
    embeddings_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L12-v2")
    print("ğŸ”„ GÃ©nÃ©ration des embeddings...")
    vectorstore = FAISS.from_texts(chunks[:batch_size], embeddings_model)

    for i in tqdm(range(batch_size, len(chunks), batch_size), desc="Progression des embeddings"):
        vectorstore.add_texts(chunks[i:i+batch_size], embedding=embeddings_model)

    vectorstore.save_local("data/nba_knowledge")
    print("âœ… Embeddings enregistrÃ©s avec succÃ¨s !")

def main():
    if not os.path.exists("data"):
        raise FileNotFoundError("ğŸš¨ Le dossier data/ est introuvable.")
    
    print("ğŸ“‚ Chargement des donnÃ©es CSV...")
    csv_text = ""
    for file in ["nba_wikipedia.csv", "nba_stats.csv", "nba_website.csv", "top_20_nba_players.csv", "learned_knowledge.csv"]:
        csv_text += load_csv_data(file) + "\n"
    
    print("âœ‚ï¸ Chunking du texte...")
    chunks = chunk_text(csv_text)

    print("ğŸ§  CrÃ©ation des embeddings...")
    create_embeddings(chunks)

    print("ğŸ‰ PrÃ©processing terminÃ© avec succÃ¨s !")

if __name__ == "__main__":
    main()
